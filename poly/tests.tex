%-*- coding: iso-latin-1 -*-
\label{chap:tests}

\paragraph{Notions :} hypothèse nulle, hypothèse alternative, statistique de
test, p-valeur, tests multiples.
\paragraph{Objectifs pédagogiques :}
\begin{itemize}      
  \setlength{\itemsep}{3pt}
\item Interpréter une p-valeur.
\item Reconnaître une situation dans laquelle un test statistique est
  approprié.
\end{itemize}


\section{Principe d'un test statistique}
\label{sec:principe_test}
Le but d'un test statistique est de déterminer la fiabilité d'une observation
faite sur une échantillon.

\begin{exemple}
  Si je lance une pièce 5 fois et obtiens 5 fois pile, puis-je en déduire que
  la pièce est déséquilibrée ? Ou ce résultat est-il dû au hasard de
  l'échantillonnage ? Qu'en est-il si j'obtiens le même résultat après 50
  lancers ?
\end{exemple}

\textbf{Un test statistique permet de déterminer si l'échantillon observé
  permet d'invalider une hypothèse qu'il était raisonnable de formuler avant
  d'observer les données.}

\begin{exemple}
  Reprenons l'exemple du lancer de pièce. Sous l'hypothèse que la pièce est
  équilibrée, la probabilité $\pi$ d'obtenir « pile » pour un lancer est $0.5$
  et celle d'obtenir pile pour 5 lancers est $0.5^5 = 3\%.$ Cette probabilité
  est faible, mais non négligeable : on a 3\% de chance d'obtenir un résultat
  aussi extrême que celui observé sur un échantillon.

  Pour 50 lancers, cette probabilité tombe à $0.5^{50} = 9.10^{-16}.$ Cette
  probabilité est extrêmement faible, et l'échantillon ne soutient pas
  l'hypothèse selon laquelle la pièce est équilibrée : nous pouvons la rejeter.
\end{exemple}

\section{Formalisme}
\label{sec:formalisme_test}
Soit $(X_1, X_2, \dots, X_n)$ un échantillon aléatoire de taille $n \in \NN^*$
d'une variable aléatoire réelle $X$ de loi $\PP_X.$ Rappelons que les
composantes $X_i$ de ce vecteur aléatoire sont indépendantes et identiquement
distribuées, de même loi que $X$. Les notions présentées dans ce chapitre
s'appliquent aussi à des variables aléatoires de nature plus complexe (par
exemple, des valeurs aléatoires multi-dimensionnelles) mais nous nous limitons
aux variables aléatoires réelles par souci de simplicité.
Nous supposons aussi disposer d'un échantillon $(x_1, x_2, \dots, x_n)$ qui est
une réalisation de $(X_1, X_2, \dots, X_n)$.

Un test statistique repose sur les éléments suivants :
\begin{itemize}
\item Une \textbf{hypothèse nulle,} notée $\HH_0$. L'hypothèse nulle est
  celle que l'on chercher à rejeter.
\item Une \textbf{hypothèse alternative,} notée $\HH_1$ ou $\HH_a$. C'est en
  général la négation de $\HH_0$.
\item Une \textbf{statistique de test,} $T$, qui sert à mesurer à quel point un
  échantillon « dévie » de l'hypothèse nulle.
\item Un \textbf{niveau de signification,} $0 < \alpha < 1$, qui est la
  probabilité de rejeter l'hypothèse nulle alors qu'elle est correcte. 
% qui sert à
  % déterminer si la probabilité d'observer, sous $\HH_0$, une statistique de
  % test au moins aussi extrême que celle observée sur l'échantillon
  % $(x_1, x_2, \dots, x_n)$ est suffisamment faible pour rejeter $\HH_0$.
\end{itemize}

Le but de cette section est de développer ces notions.

\subsection{Hypothèses de test}
Conduire un test d'hypothèse nécessite de formuler deux hypothèses :
\begin{itemize}
\item Une \textbf{hypothèse nulle,} notée $\HH_0$. Cette hypothèse doit être
  précise et permettre de faire des calculs. Le but du test est de déterminer
  s'il est raisonnable de rejeter cette hypothèse.
\item Une \textbf{hypothèse alternative,} notée $\HH_1$ ou $\HH_a$. Cette
  hypothèse est une forme de négation de $\HH_0$, et c'est l'hypothèse que l'on
  adoptera si l'hypothèse nulle est rejetée.
\end{itemize}

L'hypothèse nulle est souvent une hypothèse formulée sur la valeur un paramètre
$\theta \in \Scal \subseteq \RR$ caractérisant la loi $\PP_X$ de l'échantillon
aléatoire. Il s'agit alors de tester
\begin{equation}
  \label{eq:h0}
  \HH_0: \theta = \theta_0,
\end{equation}
où $\theta_0 \in \Scal$ est une valeur déterministe fixée à l'avance.

L'hypothèse nulle peut cependant être de nature plus complexe, par exemple :
\begin{itemize}
\item « Deux variables statistique $X$ et $Y$ sont indépendantes » (c'est le
  cas du test d'indépendance du $\chi^2$, cf. section~\ref{sec:chi2}).
\item « Deux échantillons $(x_1, x_2, \dots, x_n)$ et $(y_1, y_2, \dots, y_n)$
  sont des réalisations de la même distribution » (c'est le cas du test de
  Wilcoxon-Mann-Whitney, qui dépasse le cadre de ce programme) ;
\end{itemize}

\paragraph{Présomption d'innocence} De même que le principe de la présomption
d'innocence veut que l'on recueille suffisamment de preuves pour rejeter
l'innocence, en théorie des tests statistiques il y a présomption de
$\HH_0$. Il s'agit donc de savoir si l'échantillon observé (les preuves) est
suffisant pour rejeter $\HH_0$, ce dont on conclura $\HH_1.$ Par contre, si
l'on ne rejette pas $\HH_0$, cela peut venir soit de ce que $\HH_0$ est vraie,
soit de ce que nous n'avons pas suffisamment de données pour rejeter
$\HH_1$. Ainsi, $\HH_0$ doit être une hypothèse raisonnable, mais que l'on
aimerait avoit des raisons de réfuter.  

Dans le cadre d'une expérience scientifique, l'hypothèse $\HH_0$ correspond
ainsi à l'état actuel des connaissances. Le but d'un test statistique est de
déterminer si les données qui semblent contredire cette hypothèse sont
effectivement suffisamment improbables sous $\HH_0$ pour justifier de la
réfuter.
Dans le cadre d'un essai clinique, par exemple, l'hypothèse $\HH_0$ se doit
d'être une défavorable au nouveau médicament (« le nouveau médicament est
inefficace » ou « le nouvea médicament n'est pas plus efficace que les
traitements connus »). Le but du test statistique est de déterminer si les
données récoltées jusqu'à présent sont suffisantes pour réfuter cette
hypothèse.

\begin{exemple}
  Dans le cas de notre lancer de pièce,
  \begin{itemize}
  \item $X$ est une variable aléatoire discrète qui suit une loi de Bernoulli
    de paramètre $\pi$. $\PP_X(1) = \pi$ et $\PP_X(0) = 1-\pi$ ;
  \item l'échantillon aléatoire est un vecteur $(X_1, X_2, \dots, X_n)$ de $n$
    composantes, iid de même loi que $X$ ;
  \item une série de lancers est une réalisation $(x_1, x_2, \dots, x_n)$ de ce
    vecteur aléatoire. Dans le cas de 5 lancers tous tombant sur « pile »,
    cet échantillon est $(1, 1, 1, 1, 1)$ et $n=5.$
  \item l'hypothèse nulle est $\HH_0: \pi = 0.5.$
  \end{itemize}
\end{exemple}

Dans le cas où l'on cherche à tester la valeur d'un paramètre $\theta$ d'une
population, l'hypothèse alternative peut prendre deux formes :
\begin{itemize}
\item $\theta \neq \theta_0$, ou en d'autres termes, 
  \begin{equation}
    \label{eq:h1_bilateral}
    \HH_1: \theta < \theta_0 \text{ ou } \theta > \theta_0.
  \end{equation}
  On parle alors de test \textbf{bilatéral.}
\item Si seulement l'une des deux parties de cette hypothèse alternative nous
  intéresse, ou est possible, on parle de test \textbf{unilatéral.} Il s'agit
  alors de tester soit
  \begin{equation}
    \label{eq:h1_unilateral_gauche}
    \HH_1: \theta < \theta_0,
  \end{equation}
  soit
  \begin{equation}
    \label{eq:h1_unilateral_droite}
    \HH_1:  \theta > \theta_0.
  \end{equation}
\end{itemize}

De même que l'on élabore $\HH_0$ de sorte à ce qu'elle soit la plus plausible
avant d'avoir observé les données, on élabore $\HH_1$ en fonction de ce que
l'on espère découvrir. 

Reprenons l'exemple d'un essai clinique sur un nouveau médicament. Si
l'hypothèse $\HH_0$ est « le nouveau médicament n'a pas d'effet », on peut
poser l'hypothèse alternative $\HH_1$ : « le nouveau traitement a un effet
positif sur l'état des patients ». On espère ici non seulement rejeter
l'hypothèse nulle, mais aussi suggérer une efficacité du traitement. Cette
hypothèse est plus précise que l'hypothèse alternative selon laquelle « le
nouveau traitement a un effet sur l'état des patients », cet effet pouvant être
négatif.

\begin{exemple}
  Dans le cas de notre lancer de pièce, l'hypothèse alternative dans le cadre
  d'un test bilatéral est
  \[
    \HH_1: \pi \neq 0.5.
  \]
  Si nous rejetons $\HH_0,$ notre conclusion sera que la pièce n'est pas équilibrée.

  Dans le cadre d'un test bilatéral, par exemple 
  \[
    \HH_1: \pi > 0.5,
  \]
  si nous rejetons $\HH_0,$ notre conclusion sera que la pièce n'est pas
  équilibrée, et qu'elle favorise « pile ».

  Il ne s'agit donc pas du même test.
\end{exemple}


\subsection{Statistique de test et p-valeur}
Une \textbf{statistique de test} $T$ est une statistique de l'échantillon
aléatoire. Il s'agit donc d'une variable aléatoire réelle, fonction de
$(X_1, X_2, \dots, X_n) : T = g(X_1, X_2, \dots, X_n)$ Cette statistique de
test sert à mesurer à quel point un échantillon « dévie » de l'hypothèse nulle.

Une statistique de test est ainsi choisie de sorte à avoir une loi différente
sous $\HH_0$ et sous $\HH_1$, et de sorte à ce que sa loi sous $\HH_0$ soit
connue : c'est ce qui permettra de déterminer un critère de rejet de $\HH_0$
garantissant le niveau de signification choisi.

La plupart des test statistiques reposent sur des statistique de test dont le
développement a été long et minutieux. Le choix entre plusieurs statistiques
candidates pour un même problème est un choix difficile, qui repose entre
autres sur la validité des hypothèses sur la distribution de l'échantillon
aléatoire ou sur sa taille qui permettent de déterminer sa loi sous $\HH_0$.

\paragraph{Remarque} Pour des tests portant sur un paramètre
($\HH_0: \theta = \theta_0$), la statistique de test est souvent basée sur la
différence entre un estimateur de ce paramètre et sa valeur sous $\HH_0$.

\begin{exemple}
  Reprenons l'exemple du lancer de pièce.

  Dans la section~\ref{sec:principe_test}, nous avons choisi comme statistique
  de test $T$ le nombre de pile obtenus dans l'échantillon :
  \[
    T = \sum_{i=1}^n X_i.
  \]

  Sous $\HH_0$, autrement dit si $\pi=0.5$, la loi de $T$ est déterminée par 
  \[
    \PP(T=k) = \PP\left(\sum_{i=1}^n X_i = k\right) \text{ pour } k=0, 1,
    \dots, n.
  \]
  On reconnait ici une loi binômiale de paramètres $n$ et $\pi.$
\end{exemple}


\subsection{Niveau de signification}
Nous avons maintenant posé $\HH_0$, $\HH_1$, et une statistique de test $T$
dont nous connaissons la loi $\PP_{T0}$ sous $\HH_0$. Il nous faut maintenant
déterminer la \textbf{zone de rejet} du test, autrement dit l'ensemble
$\Ical \subseteq \RR$ de ses valeurs qui conduisent à rejeter $\HH_0$.

Pour ce faire, nous avons besoin de fixer le \textbf{niveau de signification,}
$0 < \alpha < 1$, qui est la probabilité de rejeter l'hypothèse nulle alors
qu'elle est correcte. Ce seuil est fixé à l'avance, généralement parmi
$\alpha = 1\%$, $\alpha = 5\%$ ou $\alpha = 10\%$, et détermine à quel point le
test est strict.

Ainsi, il s'agit de déterminer $\Ical \subseteq \RR$ de sorte à ce que
$\PP_{T0}(T \in \Ical) = \alpha.$

\begin{exemple}
  Dans l'exemple du lancer de pièce, nous avons choisi le nombre de pile comme
  statistique de test $T$. Sous $\HH_0 : \pi = 0.5$, $T$ suit une loi binomiale
  de paramètres $n$ (le nombre de lancers) et $\pi$.

  Posons $\alpha = 5\%.$

  Considérons le test unilatéral $\HH_1 : \pi > 0.5$. Si nous rejetons $\HH_0$,
  nous en conclurons que la pièce est biaisée en faveur du côté pile. Cela
  signifie que nous souhaitons rejeter $\HH_0$ quand le nombre de pile dans
  l'échantillon est grand. Il est ici naturel de considérer une zone de rejet
  de la forme $\Ical = \mathopen]t_0, n\mathclose].$ En d'autres termes, nous allons rejeter
  $\HH_0$ si la réalisation $t$ de $T$ sur notre échantillon est plus grande
  qu'un seuil $t_0,$ fixé tel que $\PP_{T0}(T > t_0) = \alpha.$ 

  En d'autres termes, si $F_{T0}$ est la fonction de répartition de $T$ sous
  $\HH_0$, $t_0$ est fixé de sorte à ce que $F_{T0}(t_0) = \alpha$. Dans notre
  exemple avec $n=5$ et $\alpha=0.05$, cela fixe $t_0 = 4.$

  Le test consiste donc à rejeter l'hypothèse nulle si tous les 5 lancers
  aboutissent à pile.

  Considérons maintenant le test unilatéral $\HH_1 : \pi < 0.5.$ Rejeter
  $\HH_0$ conduit à conclure que la pièce est biaisée en faveur du côté
  face. Nous considérons maintenant une zone de rejet de la forme
  $\Ical = \mathopen[0, t_0 \mathclose[,$ et $t_0$ est déterminé par
  $\PP_{T0}(T < t_0) = \alpha.$ Avec $n=5$ et $\alpha=0.05$, cela fixe
  $t_0=1$. Le test consiste donc à rejeter l'hypothèse nulle si aucun des 5
  lancers n'aboutit à pile.

  Enfin, considérons le test bilatéral $\HH_1 : \pi \neq 0.5.$ Rejeter $\HH_0$
  conduit à conclure que la pièce est biaisée, en faveur de l'un ou de l'autre
  de ses côtés. Nous considérons alors une zone de rejet de la forme
  $\Ical = \mathopen[0, t_l \mathclose[ \; \cup \; \mathopen]t_r, n
  \mathclose].$
  Il nous faut donc choisir $t_l$ et $t_r$ de sorte à ce que
  $\PP_{T0}(T < t_l) + \PP_{T0}(T > t_r) = \alpha.$ Il est assez naturel de
  fixer alors $\PP_{T0}(T < t_l) = \PP_{T0}(T > t_r) = \frac{\alpha}{2}.$ Avec
  $n=5$ et $\alpha=0.05$, on obtient $t_l = 0$ et $t_r = 5$ et il n'est donc
  jamais possible de rejeter l'hypothèse nulle.

  Le test que nous venons de définir s'appelle le test binomial. 

  \paragraph{Remarque importante} On observe ici que, parmi les trois
  hypothèses alternatives envisagées, seul le test statistique unilatéral
  $\HH_1: \pi > 0.5$ nous permet de rejeter l'hypothèse nulle. C'est une
  observation générale : un test unilatéral est plus puissant qu'un test
  bilatéral ; cependant il n'est utile que si on sait de quel côté le définir.

\end{exemple}

Dans le cas d'un test sur la valeur d'un paramètre $\theta$, c'est-à-dire avec
pour hypothèse nulle $\HH_0: \theta = \theta_0$, la zone de rejet sera de la
forme
\begin{itemize}
\item $\Ical = \mathopen]t_r, +\infty \mathclose[$ pour le test unilatéral à droite
  $\HH_1 : \theta > \theta_0$ ;
\item $\Ical = \mathopen]-\infty, t_l \mathclose[$ pour le test unilatéral à gauche
  $\HH_1 : \theta > \theta_0$ ;
\item $\Ical = \mathopen]-\infty, t_l \mathclose[ \cup
  \mathopen]t_r, +\infty \mathclose[$ pour le test bilatéral
  $\HH_1 : \theta \neq \theta_0$. 
\end{itemize}

On cherchera souvent à utiliser une statistique de test symmétrique, de sorte à
pouvoir utiliser $t_r = - t_l$.  Dans ce cas $t_0 = t_t$ est appelée
\textbf{valeur critique} du test et est telle que
\begin{itemize}
\item $\PP_{T0}(T > t_0) = \alpha$ pour le test unilatéral à droite ; 
\item $\PP_{T0}(T < - t_0) = \alpha$ pour le test unilatéral à gauche ; 
\item $\PP_{T0}(|T| > t_0) = \alpha$ pour le test bilatéral. 
\end{itemize}
Dans ce contexte, étant donné un échantillon $(x_1, x_2, \dots, x_n)$ et la
réalisation $t$ de $T$ sur cet échantillon, on appelle \textbf{p-valeur} la
probabilité $\PP_{T0}(T > t)$ pour un test unilatéral à droite (respectivement,
$\PP_{T0}(T < -t)$ pour un test unilatéral à gauche, et $\PP_{T0}(\abs{T} > t)$
pour un test bilatéral). L'hypothèse nulle est rejetée si la p-valeur est plus
petite que le niveau de signification. 

En d'autres termes, la p-valeur peut être interprétée comme la probabilité
d'obtenir, sous l'hypothèse nulle, un résultat au moins aussi extrême que celui
observé.

On rapporte ainsi généralement comme résultat d'un test non pas la statistique
de test réalisée sur l'échantillon observé, mais la p-valeur correspondante.

On lira ainsi dans des publications scientifiques des assertions suivies de «
($p < 0.05$) », siginifiant que l'assertion en question est l'hypothèse
alternative d'un test dont l'hypothèse nulle a été rejetée avec une p-valeur
inférieure à $5\%$

\begin{exemple}
  Le test que nous avons défini dans l'exemple de la pièce de monnaie s'appelle
  le test binomial. Il est implémenté dans \texttt{scipy.stats} :
  \begin{lstlisting}[language=Python]
    t = 5 # nb pile 
    n = 5 # taille échantillons 
    pi = 0.5 
    import scipy.stats as st 
    st.binom_test(t, n, pi, alternative='greater') # unilatéral à droite
  \end{lstlisting}
\end{exemple}

\subsection{Erreurs de première et deuxième espèce}
Deux types d'erreurs sont possibles quand on fait un test d'hypothèse :
\begin{itemize}
\item Rejeter l'hypothèse nulle alors qu'elle est correcte : on parle d'une
  \textbf{erreur de première espèce}, ou \textbf{erreur de Type I}.
\item Accepter l'hypothèse nulle alors qu'elle est en fait fausse : on parle
  d'une \textbf{erreur de deuxième espèce}, ou \textbf{erreur de Type II}.
\end{itemize}

\paragraph{Moyen mnémotechnique} Ces deux types d'erreur sont numérotées dans
le même ordre que dans l'histoire du garçon qui criait au loup : d'abord les
villageois pensaient qu'il y avait un loup alors qu'il n'y en avait pas (erreur
de première espèce), mais à la fin les villageois pensaient qu'il n'y avait pas
de loup alors qu'il y en avait un (erreur de deuxième espèce). Ici l'hypothèse
nulle est l'hypothèse correspondant à l'état « par défaut » du village, à
savoir sans loup.

Le niveau de signification $\alpha$ est ainsi la probabilité de commettre une
erreur de première espèce.

La probabilité de commettre une erreur de deuxième espèce est généralement noté
$\beta$. La probabilité de rejeter $\HH_0$ à raison, $1-\beta$, est appelée la
\textbf{puissance} du test.


\section{Comparaison d'une moyenne observée à une moyenne théorique}
\label{sec:test_moyenne}
Dans cette section, nous allons dérouler un autre exemple de test statistique. 

Nous souhaitons tester l'hypothèse selon laquelle les pigeons du Jardin du
Luxembourg ont un poids moyen de 300g. Nous disposons de mesures pour 40
pigeons, capturés et pesés par des élèves de l'École, dont la moyenne est de
350g et l'écart-type 30g.

Définissons une variable aléatoire réelle, de carré intégrable pour nous
simplifier la vie, $X$. $X$ modélise le poids d'un pigeon. Posons $\mu$
l'espérance de $X$ et $\sigma^2$ sa variance.

Nous posons $n=40$ ; les poids des 40 pigeons, $(x_1, x_2, \dots, x_n)$, sont
la réalisation de l'échantillon aléatoire $(X_1, X_2, \dots, X_n)$ composé de
variables aléatoires indépendantes et identiquement distribuées de même loi que
$X$.

Nous posons l'hypothèse nulle à tester
\[
  \HH_0 : \mu = \mu_0, 
\]
avec $\mu_0 = 300g.$

Nous n'avons aucun a priori sur le poids des pigeons du Jardin du Luxembourg,
et formulons donc l'hypothèse alternative bilatérale
\[
  \HH_1 : \mu \neq \mu_0.
\]

Pour tester $\HH_0$, nous souhaitons déterminer la probabilité d'observer une
moyenne empirique $\hat{m}$ de 350g si l'espérance de $X$ est de 300g.  En
posant $M_n$ la moyenne empirique de l'échantillon, nous souhaitons déterminer
$\PP(M_n=\hat{m}|\mu=\mu_0)$.

Le théorème central limite nous indique que 
\[
  \frac{\sqrt{n} (M_n - \mu)}{\sigma}  \cvloi \Ncal(0, 1).
\]

Nous ne connaissons pas la variance $\sigma^2$ de $X$ ; cependant nous pouvons
l'estimer grâce à l'écart-type empirique $\hat{\sigma} = 30g,$ et utiliser 
\[
  \frac{\sqrt{n} (M_n - \mu)}{\hat \sigma}  \cvloi \Ncal(0, 1).
\]
Nous ne remplaçons pas $\mu$ par son estimation $\hat{m}$ : ce n'aurait aucun
sens, car nous cherchons justement à tester sa valeur.





TODO test pour comparer la moyenne de deux échantillons, par exemple cas et
contrôles dans un essai clinique.







\subsection{Intervalle de confiance}
TODO REF Probabilités V

\section{Test d'indépendance du $\chi^2$}
\label{sec:chi2}

\section{Tests d'hypothèses multiples}
\label{sec:mht}


\begin{plusloin}
\item La \textbf{puissance} d'un test statistique est la probabilité de rejeter
  $\HH_0$ si elle est fausse. C'est le complément à 1 de l'erreur de deuxième
  espèce (erreur de Type II), qui consiste à ne pas rejeter $\HH_0$ alors
  qu'elle et fausse. La puissance est généralement délicate à évaluer car elle
  nécessite de spécifier correctement $\HH_1$. 
\item On dit d'un test statistique qu'il est sans biais si TODO
\item On dit d'un test statistique qu'il converge si TODO
\item Si la distribution de la statistique de test sous l'hypothèse nulle n'est
  pas connue, on peut recourir à sa distribution empirique. Cette dernière est
  obtenue par une technique de permutations. TODO
\item TODO ``Controverse'' autour des p-valeurs
\end{plusloin}
