{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC5 - Sélection de modèles et régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook aborde les notions de régularisation et de sélection de modèles :\n",
    "- La régularisation consiste à imposer des contraintes supplémentaires à votre modèle pour lui éviter de surapprendre sur les données d'entraînement. Ici nous présentons les **régularisations L1 et L2** (partie 1).\n",
    "- La sélection de modèle consiste à élaborer des protocoles d'évaluation robustes pour comparer les performances de différents modèles sur un problème donné. La technique utilisée est celle de la **validation croisée** (partie 2).\n",
    "- Un problème concret sur une base de données réelle permet de mettre en applications les concepts introduits (partie 3).\n",
    "\n",
    "Enfin, de part les exemples présentés, une variante de la régression linéaire est présentée : la **régression polynomiale**. \n",
    "\n",
    "Ce notebook vous est proposé par [Arthur Imbert](https://github.com/Henley13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:43.687796Z",
     "start_time": "2020-06-09T13:09:42.508696Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a été créé avec les versions suivantes : \n",
    "- numpy==1.18.3\n",
    "- matplotlib==3.1.1\n",
    "- pandas==1.0.3\n",
    "- sklearn==0.23.1\n",
    "- scipy==1.3.1\n",
    "\n",
    "Des différences de version peuvent expliquer des comportements inattendus (avertissements, messages d'erreurs, fonctionalités inexistantes) mais il n'est pas nécessaire a priori d'avoir exactement les versions listées ci-dessus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:43.694478Z",
     "start_time": "2020-06-09T13:09:43.689725Z"
    }
   },
   "outputs": [],
   "source": [
    "# check your versions\n",
    "print(\"numpy=={0}\".format(np.__version__))\n",
    "print(\"matplotlib=={0}\".format(matplotlib.__version__))\n",
    "print(\"pandas=={0}\".format(pd.__version__))\n",
    "print(\"sklearn=={0}\".format(sklearn.__version__))\n",
    "print(\"scipy=={0}\".format(scipy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:43.699299Z",
     "start_time": "2020-06-09T13:09:43.696637Z"
    }
   },
   "outputs": [],
   "source": [
    "# set font size in plots\n",
    "plt.rc('font', **{'size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:43.793918Z",
     "start_time": "2020-06-09T13:09:43.701292Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modèle complexe a plus de chance de surapprendre. C'est le cas par exemple si vous avez un grand nombre de variables ou plusieurs paramètres à optimiser pour faire fonctionner le modèle. En général, la régularisation prend la forme d'un terme additionel dans la fonction de perte qui pénalise les modèles complexes. L'idée est d'introduire volontairement un biais dans le modèle pour le rendre plus robuste. Nous préférons un modèle un peu moins précis sur les données d'entraînement, mais capable de conserver le même niveau de performance sur de nouvelles données de test. \n",
    "\n",
    "Nous allons utiliser dans ce notebook deux méthodes parmi les plus couramment utilisées pour régulariser les modèles linéaires :\n",
    "- [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) cf. Section 8.5 du poly\n",
    "- [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) cf. Section 8.6 du poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Régularisation L2 (Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **régularisation L2** appliquée à une régression linéaire (également appelé **régression Ridge**) consiste à résoudre le problème convexe suivant :\n",
    "\n",
    "$$\n",
    "    \\underset{\\beta \\in \\mathbb{R}^{p+1}}{\\arg\\min} \\lVert y - X\\beta \\rVert^2_2 + \\lambda \\lVert \\beta \\rVert^2_2\n",
    "$$\n",
    "\n",
    "Le terme $\\lVert \\beta \\rVert^2_2$ pénalise les valeurs extrêmes de $\\beta$. Intuitivement nous pouvons voir que cette contrainte va inciter le modèle à ne pas trop se spécialiser \" la solution n'associe pas des poids exagérés à des dimensions de $X$ qui permettrait éventuellement de prédire parfaitement les données d'entraînement. \n",
    "\n",
    "Le paramètre $\\lambda$ permet d'accorder plus ou moins d'importance à votre terme de régularisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour illustrer l'impact d'une régularisation Ridge, nous allons simuler un jeu de données non linéaire qui prendra la forme d'une courbe sinusoïdale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:43.802971Z",
     "start_time": "2020-06-09T13:09:43.796332Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_samples = 30\n",
    "\n",
    "# set the random seed to generate the same random numbers\n",
    "np.random.seed(13)\n",
    "\n",
    "# ground truth function such that y = f(X)\n",
    "def f(X):\n",
    "    return np.cos(1.5 * np.pi * X) * 5\n",
    "\n",
    "# compute ground truth distribution\n",
    "X_gt = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "y_gt = f(X_gt)\n",
    "print(X_gt.shape, y_gt.shape)\n",
    "\n",
    "# simulate random samples from this distribution\n",
    "X = np.sort(np.random.rand(nb_samples, 1))\n",
    "y = f(X)\n",
    "\n",
    "# add noise\n",
    "y += np.random.randn(nb_samples, 1) * 0.3\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.059326Z",
     "start_time": "2020-06-09T13:09:43.804882Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot ground truth function f\n",
    "plt.plot(X_gt, y_gt, label=\"True function\", c=\"orange\", linewidth=2)\n",
    "\n",
    "# plot samples\n",
    "plt.scatter(X, y, label=\"Observed samples\", c=\"forestgreen\", marker=\"o\", s=50)\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"X\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"y\", fontweight=\"bold\", fontsize=15)\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-7, 7))\n",
    "plt.title(\"y = f(X)\", fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons 3 méthodes pour estimer au mieux cette courbe à partir d'une \"droite\" de régression :\n",
    "- Une régression linéaire\n",
    "- Une régression polynomiale\n",
    "- Une régression polynomiale régularisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.065948Z",
     "start_time": "2020-06-09T13:09:44.060710Z"
    }
   },
   "outputs": [],
   "source": [
    "# split dataset for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Combien de *features* avons-nous dans notre problème ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainons une régression linéaire « classique » (comme celle vue à la PC3) sur `(X_train, y_train)` et évaluons sa performance d'une part sur le jeu d'entraînement et d'autre part sur le jeu de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi comparer ces deux performances ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.077724Z",
     "start_time": "2020-06-09T13:09:44.068803Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# adjusted R2\n",
    "print(\"adjusted R2\")\n",
    "r2_score_reg_train = r2_score(y_train, reg.predict(X_train))\n",
    "print(\"\\r train: {0:0.2f}\".format(r2_score_reg_train))\n",
    "\n",
    "r2_score_reg_test = r2_score(y_test, reg.predict(X_test))\n",
    "print(\"\\r test: {0:0.2f}\".format(r2_score_reg_test))\n",
    "\n",
    "# mean squared error\n",
    "print(\"root mean squared error\")\n",
    "rmse_reg_train = mean_squared_error(y_train, reg.predict(X_train), squared=False)\n",
    "print(\"\\r train: {0:0.2f}\".format(rmse_reg_train))\n",
    "\n",
    "rmse_reg_test = mean_squared_error(y_test, reg.predict(X_test), squared=False)\n",
    "print(\"\\r test: {0:0.2f}\".format(rmse_reg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix de la régression linéaire ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.082579Z",
     "start_time": "2020-06-09T13:09:44.079940Z"
    }
   },
   "outputs": [],
   "source": [
    "# interpolate regression line\n",
    "y_model = reg.predict(X_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant afficher le modèle appris sur le graphe précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.401998Z",
     "start_time": "2020-06-09T13:09:44.084941Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot ground truth function f\n",
    "plt.plot(X_gt, y_gt, '--', label=\"True function\", c=\"orange\", linewidth=2)\n",
    "\n",
    "# plot regression line\n",
    "plt.plot(X_gt, y_model, label=\"Learned function\", c=\"steelblue\", linewidth=2)\n",
    "\n",
    "# plot train and test samples\n",
    "plt.scatter(X_train, y_train, label=\"Train samples\", c=\"steelblue\", marker=\"X\", s=50)\n",
    "plt.scatter(X_test, y_test, label=\"Test samples\", c=\"firebrick\", marker=\"D\", s=50)\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"X\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"y\", fontweight=\"bold\", fontsize=15)\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-7, 7))\n",
    "plt.title(\"Linear regression\", fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Le graphique est-il cohérent avec les performances calculées ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Régression polynomiale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régression polynomiale consiste à apprendre un modèle non-linéaire en apprenant un modèle linéaire sur un nouvel ensemble de variables, formé de monomes des variables décrivant nos données.\n",
    "\n",
    "De manière générale, pour un problème décrit par $p$ variables $(X_1, X_2, \\dots, X_p)$, une régression polynomiale de degré $d$ est une régression linéaire sur les variables $(X_1, X_2, \\dots, X_p, X_1^2, X_1 X_2, \\dots, X_p^2, \\dots, X_p^d)$. Remarquez que nous créons ainsi un grand nombre de variables, corrélées entre elles ; nous gagnons en finesse de modélisation, mais perdons en complexité du modèle, risque de surapprentissage, et fléau de la dimension. Nous parlerons plus de modèles non-linéaires au chapitre 9. \n",
    "\n",
    "Une telle transformation est possible avec la classe `PolynomialFeatures` de `sklearn.preprocessing`.\n",
    "\n",
    "Ici, il s'agit donc de régresser une droite à partir des puissances de $X$ et non plus de $X$ uniquement. Dans notre exemple, $\\beta$ n'est plus un scalaire mais un vecteur associant un coefficient à $X^1$, $X^2$, $X^3$, ..., $X^{15}$. On approxime $y$ comme un polynôme de $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.408684Z",
     "start_time": "2020-06-09T13:09:44.403662Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute polynomial features\n",
    "polynomial_features = PolynomialFeatures(degree=15, include_bias=False)\n",
    "\n",
    "X_train_polynomial = polynomial_features.fit_transform(X_train)\n",
    "X_test_polynomial = polynomial_features.transform(X_test)\n",
    "X_gt_polynomial = polynomial_features.transform(X_gt)\n",
    "\n",
    "print(X_train_polynomial.shape)\n",
    "print(X_test_polynomial.shape)\n",
    "print(X_gt_polynomial.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Combien de *features* avons-nous dans notre problème ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.419324Z",
     "start_time": "2020-06-09T13:09:44.410220Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_polynomial, y_train)\n",
    "\n",
    "# adjusted R2\n",
    "print(\"adjusted R2\")\n",
    "r2_score_reg_train = r2_score(y_train, reg.predict(X_train_polynomial))\n",
    "print(\"\\r train: {0:0.2f}\".format(r2_score_reg_train))\n",
    "r2_score_reg_test = r2_score(y_test, reg.predict(X_test_polynomial))\n",
    "print(\"\\r test: {0:0.2f}\".format(r2_score_reg_test))\n",
    "\n",
    "# root mean squared error\n",
    "print(\"root mean squared error\")\n",
    "rmse_reg_train = mean_squared_error(y_train, reg.predict(X_train_polynomial), squared=False)\n",
    "print(\"\\r train: {0:0.2f}\".format(rmse_reg_train))\n",
    "rmse_reg_test = mean_squared_error(y_test, reg.predict(X_test_polynomial), squared=False)\n",
    "print(\"\\r test: {0:0.2f}\".format(rmse_reg_test))\n",
    "\n",
    "# interpolate regression line\n",
    "y_model = reg.predict(X_gt_polynomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix de la régression polynomiale ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant comparer le modèle appris à la vérité terrain (la fonction qui nous a servi à simuler les données)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.728903Z",
     "start_time": "2020-06-09T13:09:44.421123Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot ground truth function f\n",
    "plt.plot(X_gt, y_gt, '--', label=\"True function\", c=\"orange\", linewidth=2)\n",
    "\n",
    "# plot regression line\n",
    "plt.plot(X_gt, y_model, label=\"Learned function\", c=\"steelblue\", linewidth=2)\n",
    "\n",
    "# plot train and test samples\n",
    "plt.scatter(X_train, y_train, label=\"Train samples\", c=\"steelblue\", marker=\"X\", s=50)\n",
    "plt.scatter(X_test, y_test, label=\"Test samples\", c=\"firebrick\", marker=\"D\", s=50)\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"X\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"y\", fontweight=\"bold\", fontsize=15)\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-7, 7))\n",
    "plt.title(\"Polynomial regression\", fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Le graphique est-il cohérent avec les performances calculées ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Régression polynomiale régularisée ridge\n",
    "\n",
    "Comme la régression polynomiale surapprend, nous allons maintenant lui appliquer un terme de régularisation ridge pour essayer de compenser cet effet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:44.741457Z",
     "start_time": "2020-06-09T13:09:44.730735Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "ridge = Ridge(alpha=0.01, random_state=13)\n",
    "ridge.fit(X_train_polynomial, y_train)\n",
    "\n",
    "# adjusted R2\n",
    "print(\"adjusted R2\")\n",
    "r2_score_ridge_train = r2_score(y_train, ridge.predict(X_train_polynomial))\n",
    "print(\"\\r train: {0:0.2f}\".format(r2_score_ridge_train))\n",
    "r2_score_ridge_test = r2_score(y_test, ridge.predict(X_test_polynomial))\n",
    "print(\"\\r test: {0:0.2f}\".format(r2_score_ridge_test))\n",
    "\n",
    "# mean squared error\n",
    "print(\"root mean squared error\")\n",
    "rmse_ridge_train = mean_squared_error(y_train, ridge.predict(X_train_polynomial), squared=False)\n",
    "print(\"\\r train: {0:0.2f}\".format(rmse_ridge_train))\n",
    "rmse_ridge_test = mean_squared_error(y_test, ridge.predict(X_test_polynomial), squared=False)\n",
    "print(\"\\r test: {0:0.2f}\".format(rmse_ridge_test))\n",
    "\n",
    "# interpolate regression line\n",
    "y_model = ridge.predict(X_gt_polynomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix du Ridge ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparons le modèle que nous venons d'apprendre à la fonction nous ayant permi de simuler les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.039183Z",
     "start_time": "2020-06-09T13:09:44.743127Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot ground truth function f\n",
    "plt.plot(X_gt, y_gt, '--', label=\"True function\", c=\"orange\", linewidth=2)\n",
    "\n",
    "# plot regression line\n",
    "plt.plot(X_gt, y_model, label=\"Learned function\", c=\"steelblue\", linewidth=2)\n",
    "\n",
    "# plot train and test samples\n",
    "plt.scatter(X_train, y_train, label=\"Train samples\", c=\"steelblue\", marker=\"X\", s=50)\n",
    "plt.scatter(X_test, y_test, label=\"Test samples\", c=\"firebrick\", marker=\"D\", s=50)\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"X\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"y\", fontweight=\"bold\", fontsize=15)\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-7, 7))\n",
    "plt.title(\"Polynomial regression + L2 regularization\", fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Avec la régression polynomiale, était-il possible d'éviter le surapprentissage sans utiliser la régularisation L2 ? \n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Régularization L1 (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **régularisation L1** appliquée à une régression linéaire (également appelé **régression Lasso**) consiste à résoudre le problème suivant :\n",
    "\n",
    "$$\n",
    "    \\underset{\\beta \\in \\mathbb{R}^{p+1}}{\\arg\\min} \\lVert y - X\\beta \\rVert^2_2 + \\lambda \\lVert \\beta \\rVert_1\n",
    "$$\n",
    "\n",
    "L'impact de la pénalisation L1 est plus radical que celui de la pénalisation L2. Le terme $\\lVert \\beta \\rVert_1$ pénalise tous les coefficients non nuls. Cette contrainte va inciter le modèle à mettre à zéro les coefficients des variables les moins influentes. La solution est dite parcimonieuse ou *sparse* (un nombre limité de coefficients non nuls). Le paramètre $\\lambda$ permet d'accorder plus ou moins d'importance à votre terme de régularisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour illustrer l'impact d'une régularisation Lasso, nous allons simuler un jeu de données parcimonieux à approximer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.047049Z",
     "start_time": "2020-06-09T13:09:45.040876Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_samples = 100\n",
    "nb_features = 200\n",
    "noise_ratio = 0.1\n",
    "\n",
    "# set the random seed to generate the same random numbers\n",
    "np.random.seed(13)\n",
    "\n",
    "# sample random multidimensional input\n",
    "X = np.random.randn(nb_samples, nb_features)\n",
    "\n",
    "# decreasing coefficients with alternated signs for visualization\n",
    "idx = np.arange(nb_features)\n",
    "beta = (-1) ** idx * np.exp(-idx / 10)\n",
    "\n",
    "# sparsify coefficients\n",
    "beta[10:] = 0\n",
    "\n",
    "# target variable\n",
    "y = np.dot(X, beta)\n",
    "\n",
    "# add noise\n",
    "y += np.random.randn(nb_samples) * noise_ratio\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.355782Z",
     "start_time": "2020-06-09T13:09:45.049374Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot ground truth coefficient values\n",
    "nonzero_coef_id = np.where(beta)[0]\n",
    "nonzero_coef_value = beta[beta != 0]\n",
    "m, s, _ = plt.stem(idx, beta, \n",
    "                   markerfmt='o', label='True coefficients', use_line_collection=True)\n",
    "plt.setp([m, s], color=\"firebrick\", linewidth=2)\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"Coefficients\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"Coefficient value\", fontweight=\"bold\", fontsize=15)\n",
    "plt.title(\"Sparse dataset\", fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la proportion de coefficients non nuls utilisées pour simuler les données ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici la difficulté pour l'apprentissage vient de ce qu'une grande partie de notre jeu de données n'a pas d'influence sur notre variable d'intérêt $y$. A nouveau, nous commençons par entraîner une régression linéaire afin de comparer les résultats avec le Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.361591Z",
     "start_time": "2020-06-09T13:09:45.357728Z"
    }
   },
   "outputs": [],
   "source": [
    "# split dataset for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.377079Z",
     "start_time": "2020-06-09T13:09:45.363149Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# adjusted R2\n",
    "print(\"adjusted R2\")\n",
    "r2_score_reg_train = r2_score(y_train, reg.predict(X_train))\n",
    "print(\"\\r train: {0:0.2f}\".format(r2_score_reg_train))\n",
    "r2_score_reg_test = r2_score(y_test, reg.predict(X_test))\n",
    "print(\"\\r test: {0:0.2f}\".format(r2_score_reg_test))\n",
    "\n",
    "# mean squared error\n",
    "print(\"root mean squared error\")\n",
    "rmse_reg_train = mean_squared_error(y_train, reg.predict(X_train), squared=False)\n",
    "print(\"\\r train: {0:0.2f}\".format(rmse_reg_train))\n",
    "rmse_reg_test = mean_squared_error(y_test, reg.predict(X_test), squared=False)\n",
    "print(\"\\r test: {0:0.2f}\".format(rmse_reg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix de la régression linéaire ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Régression linéaire régularisée Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Code :__ Entrainez une régression Lasso (paramètre de régularisation `alpha=0.1`) sur les données d'entraînement. Reportez-vous à la documentation : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html (l'API est similaire à celle de la régularisation ridge).\n",
    "\n",
    "Calculez le R2 ajusté et la *RMSE* sur les données d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.382044Z",
     "start_time": "2020-06-09T13:09:45.379114Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "lasso = None\n",
    "\n",
    "# adjusted R2\n",
    "# ...\n",
    "\n",
    "# mean squared error\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix du Lasso ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant visualiser les coefficients du modèle appris par le Lasso : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.948030Z",
     "start_time": "2020-06-09T13:09:45.399797Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot ground truth coefficient values\n",
    "nonzero_coef_id = np.where(beta)[0]\n",
    "nonzero_coef_value = beta[beta != 0]\n",
    "m, s, _ = plt.stem(nonzero_coef_id, nonzero_coef_value, \n",
    "                   markerfmt='o', label='True coefficients', use_line_collection=True)\n",
    "plt.setp([m, s], color=\"firebrick\", linewidth=2)\n",
    "\n",
    "# plot linear coefficient values\n",
    "nonzero_coef_id = np.where(reg.coef_)[0]\n",
    "nonzero_coef_value = reg.coef_[reg.coef_ != 0]\n",
    "m, s, _ = plt.stem(nonzero_coef_id, nonzero_coef_value, \n",
    "                   markerfmt='D', label='Linear coefficients', use_line_collection=True)\n",
    "plt.setp([m, s], color=\"steelblue\", linewidth=2)\n",
    "\n",
    "# plot Lasso coefficient values\n",
    "nonzero_coef_id = np.where(lasso.coef_)[0]\n",
    "nonzero_coef_value = lasso.coef_[lasso.coef_ != 0]\n",
    "m, s, _ = plt.stem(nonzero_coef_id, nonzero_coef_value, \n",
    "                   markerfmt='X', label='Lasso coefficients', use_line_collection=True)\n",
    "plt.setp([m, s], color=\"forestgreen\", linewidth=2)\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"Coefficients\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"Estimated value\", fontweight=\"bold\", fontsize=15)\n",
    "title_str = \"Linear $R^2$: {0:0.2f} | Lasso $R^2$: {01:0.2f}\".format(r2_score_reg_test, r2_score_lasso_test)\n",
    "plt.title(title_str, fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Combien de variables sont utilisées par le modèle lasso ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comment expliquer les mauvaises performances de la régression linéaire (non régularisée) ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sélection de modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.954892Z",
     "start_time": "2020-06-09T13:09:45.952099Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre objectif est de sélectionner le meilleur modèle pour un problème donné. Pour comparer différent modèles nous utilisons un ou plusieurs critères de performance sur un jeu de données que l'on aurait exclue dès le début de l'analyse (le jeu de test).\n",
    "\n",
    "En particulier, nous avons utilisé une valeur fixe du coefficient de régularisation (`alpha` dans `scikit-learn`, $\\lambda$ dans le poly). Rien ne garantit que cette valeur soit optimale.\n",
    "\n",
    "Jusqu'à maintenant, séparer les observations en jeu d'entraînement et de test suffisait à entraîner et évaluer les modèles. Cependant, pour des problèmes plus complexes nécessitant des modèles plus élaborées, une préparation des données en amont et un traitement particulier des résultats en aval, il est très facile de surapprendre sur les données de test elles-mêmes ! Vous risquez d'optimisez votre chaîne d'analyse (le poids $\\lambda$ de la régularisation, le choix des variables à conserver, etc.) afin de maximiser les performances sur un jeu de test qui n'est plus totalement inconnu. Une solution est de séparer vos observations initiales en trois jeux de données : **entraînement** (pour entraîner les modèles), **validation** (pour sélectionner le meilleur modèle et optimiser ses paramètres) et **test** (pour évaluer).\n",
    "\n",
    "La **validation croisée** permet d'aller plus loin et de répéter les séparations *entraînement/test* ou *entraînement/validation/test* à partir du même jeu d'observations. Les mesures de performances moyennées sur ces différentes séparations sont plus robustes. \n",
    "\n",
    "Reportez-vous à la section 8.2 du poly pour ces notions. \n",
    "\n",
    "`sklearn` propose différentes variantes de la validation croisée :\n",
    "- [K-fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) : la validation croisée telle que nous l'avons vue dans le poly\n",
    "- [Stratified K-fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) : même chose, mais pour les problèmes de classification, en faisant en sorte que la proportion d'exemples de chaque classe soit respectée dans chaque fold\n",
    "\n",
    "(Pour aller plus loin)\n",
    "- [Leave-One-Out](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html) : autant de folds que d'échantillons ; requiert donc d'entrainer $n$ modèles (ce qui est coûteux en ressources) et a l'inconvénient de produire des modèles très similaire les uns aux autres (leurs jeux d'entrainement différant d'une seule observation) qui, étant testés sur une observation à la fois, peuvent donner une grande variance dans l'estimation de l'erreur de généralisation. Elle est ainsi peu utilisée, sauf cas particulier.\n",
    "- [Leave-P-Out](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html) : chaque sous ensemble de taille $P$ du jeu de données est utilisé comme jeu de test (et le reste comme jeu d'entrainement) ; on obtient ainsi un grand nombre de modèles (ce qui peut être très coûteux en ressources) et des jeux de tests non disjoints (contrairement à la validation croisée). Relativement peu utilisé aussi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la suite, nous utilisons le même jeu de données parcimonieux que pour le Lasso. La validation croisée permet une évaluation plus robuste de notre modèle, mais également d'optimiser le paramètre de régularisation $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour générer de nouveau le jeu de données si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.962888Z",
     "start_time": "2020-06-09T13:09:45.956823Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_samples = 100\n",
    "nb_features = 200\n",
    "noise_ratio = 0.1\n",
    "\n",
    "# set the random seed to generate the same random numbers\n",
    "np.random.seed(13)\n",
    "\n",
    "# sample random multidimensional input\n",
    "X = np.random.randn(nb_samples, nb_features)\n",
    "\n",
    "# decreasing coefficients with alternated signs for visualization\n",
    "idx = np.arange(nb_features)\n",
    "beta = (-1) ** idx * np.exp(-idx / 10)\n",
    "\n",
    "# sparsify coefficients\n",
    "beta[10:] = 0\n",
    "\n",
    "# target variable\n",
    "y = np.dot(X, beta)\n",
    "\n",
    "# add noise\n",
    "y += np.random.randn(nb_samples) * noise_ratio\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant `sklearn.model_selection.train_test_split` et `sklearn.model_selection.KFold` nous isolons un jeu de test dès le début, puis nous tirons aléatoirement K *folds* d'entraînement et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:45.989559Z",
     "start_time": "2020-06-09T13:09:45.965310Z"
    }
   },
   "outputs": [],
   "source": [
    "# define different train-validation-test splits\n",
    "X_train_, X_test, y_train_, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "print(\"nb_test: {1}\".format(len(X_train_), len(X_test)), \"\\n\")\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "\n",
    "# loop over the different folds\n",
    "scores = []\n",
    "for i, (train_index, validation_index) in enumerate(kf.split(X_train_)):\n",
    "    print(\"fold: {0} | nb_train: {1} | nb_validation: {2}\".format(i, len(train_index), len(validation_index)))\n",
    "\n",
    "    # get train and validation dataset\n",
    "    X_train = X_train_[train_index]\n",
    "    X_validation = X_train_[validation_index]\n",
    "    y_train = y_train_[train_index]\n",
    "    y_validation = y_train_[validation_index]\n",
    "    \n",
    "    # preprocess data\n",
    "    # ...\n",
    "    \n",
    "    # train model\n",
    "    lasso = Lasso(alpha=0.1)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    # postprocess results\n",
    "    # ...\n",
    "    \n",
    "    # measure performance (here, adjusted R2)\n",
    "    r2_score_lasso_validation = r2_score(y_validation, lasso.predict(X_validation))\n",
    "    scores.append(r2_score_lasso_validation)\n",
    "    print(\"\\r adjusted R2 (validation): {0:0.3f}\".format(r2_score_lasso_validation))\n",
    "    \n",
    "print()\n",
    "\n",
    "# performance on the validation set\n",
    "average_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "print(\"Average adjusted R2 (validation): {0:0.3f}\".format(average_score))\n",
    "print(\"Standard deviation adjusted R2 (validation): {0:0.3f}\".format(std_score), \"\\n\")\n",
    "\n",
    "# performance on the test set\n",
    "r2_score_lasso_test = r2_score(y_test, lasso.predict(X_test))\n",
    "print(\"Adjusted R2 (test): {0:0.3f}\".format(r2_score_lasso_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus simplement, on peut directement calculer une métrique de performance en moyennant plusieurs folds avec `sklearn.model_selection.cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:46.016822Z",
     "start_time": "2020-06-09T13:09:45.991980Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a model\n",
    "lasso = Lasso(alpha=0.1, random_state=13, max_iter=10000)\n",
    "\n",
    "# compute an average adjusted R2 score over 5 different train-test folds\n",
    "cv_results = cross_validate(lasso, X, y, cv=5, return_train_score=True, scoring=\"r2\")\n",
    "print(\"Average adjusted R2 (test): {0:0.3f}\".format(np.mean(cv_results[\"test_score\"])))\n",
    "print(\"Standard deviation adjusted R2 (test): {0:0.3f}\".format(np.std(cv_results[\"test_score\"])))\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Selon vous, qu'est-ce qui pourrait expliquer la différence de performance entre les méthodes présentées (la première avec `sklearn.model_selection.KFold` et la seconde avec `sklearn.model_selection.cross_validate`) ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Code :__ Vous allez coder une validation croisée sur 5 *folds* en séparant les données entre entraînement et test seulement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:46.021429Z",
     "start_time": "2020-06-09T13:09:46.018914Z"
    }
   },
   "outputs": [],
   "source": [
    "# define different train-test splits\n",
    "# ...\n",
    "\n",
    "# loop over the different folds\n",
    "# ...\n",
    "\n",
    "# performance on the test set\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 *Gridsearch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le **_gridsearch_** consiste à évaluser les performances pour différentes valeurs de paramètres sur différents *folds* de validation croisée afin de retourner le paramètre optimal. La fonction d'usage est `sklearn.model_selection.GridSearchCV`. Dans notre exemple il s'agit d'optimiser le paramètre `alpha` du modèle Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:46.813439Z",
     "start_time": "2020-06-09T13:09:46.047317Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model and alpha values to evaluate\n",
    "lasso = Lasso(random_state=13, max_iter=10000)\n",
    "alphas = np.logspace(-4, -1, 30)\n",
    "\n",
    "# define gridsearch\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "nb_folds = 5\n",
    "grid = GridSearchCV(lasso, tuned_parameters, cv=nb_folds, refit=False)\n",
    "\n",
    "# run gridsearch\n",
    "grid.fit(X, y)\n",
    "\n",
    "# get adjusted R2 (default score with Lasso models)\n",
    "scores = grid.cv_results_['mean_test_score']\n",
    "scores_std = grid.cv_results_['std_test_score']\n",
    "\n",
    "# compute standard errors\n",
    "std_error = scores_std / np.sqrt(nb_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Code :__ A partir des résultats du *gridsearch*, récupérez la valeur `alpha` optimale ainsi que la performance maximale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:14:16.474736Z",
     "start_time": "2020-06-09T13:14:16.472622Z"
    }
   },
   "outputs": [],
   "source": [
    "# get optimal alpha\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:47.313286Z",
     "start_time": "2020-06-09T13:09:46.821062Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot scores with a log scale in x-axis\n",
    "plt.semilogx(alphas, scores, label=\"Average adjusted R2\")\n",
    "plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "# control the translucency of the fill color with alpha=0.2\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "# plot best score\n",
    "plt.axhline(np.max(scores), linestyle=':', color=\"firebrick\", label=\"Best adjusted R2\")\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"alpha\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"CV score +/- std error\", fontweight=\"bold\", fontsize=15)\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title(\"Gridsearch results (score = adjusted R2)\", fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que voudrais dire une valeur de `alpha` proche de 0 ? Une valeur proche de 1 ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ce stade, vous pouvez entraîner votre modèle optimal en utilisant ensemble vos données d'entraînement et de validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cas pratique (bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce cas pratique nous utilisons des données cliniques. L'objectif est de **prédire le niveau d'antigène prostatique spécifique** (a.k.a. *PSA* pour *Prostate-Specific Antigen*). C'est une protéine produite exclusivement par la prostate. Un taux de concentration élevé de cette molécule dans le sang est souvent le signe chez l'homme d'un cancer de la prostate. Cet indicateur permet ainsi de suivre l'évolution du cancer.\n",
    "\n",
    "Plus précisément, nous allons essayer de prédire le niveau de concentration du *PSA* (`lpsa`, en échelle logarithmique) à partir des mesures cliniques suivantes :\n",
    "- `cavol` : Le volume de la tumeur (échelle logarithmique).\n",
    "- `lweight` : Le poids de la prostate (échelle logarithmique).\n",
    "- `age`: L'âge du patient.\n",
    "- `lbph`: Le volume de l'hypertrophie bénigne de la prostate (a.k.a. *BPH* pour *Benign Prostatic Hyperplasia*) qui correspond au volume non cancéreux de l'organe (échelle logarithmique).\n",
    "- `svi`: Indicateur sur le fait que le cancer s'est propagé aux vésicules séminales (deux glandes associées à la prostate).\n",
    "- `lcp`: La *pénétration capsulaire* qui mesure à quel point la capsule prostatique (la membrane qui entoure la prostate), a été envahi par le cancer (échelle logarithmique).\n",
    "- `gleason`: Le score *Gleason*. Ce score est établi par un histopathologiste après observation d'une biopsie de la prostate. Pour plus d'information vous pouvez consulter ce lien : http://www.wikiwand.com/en/Gleason_grading_system. \n",
    "* `pgg45`: Le pourcentage de la tumeur qui est accrédité d'un score *Gleason* de 4 ou 5.\n",
    "\n",
    "Ce jeu de données est un jeu de données classique, que l'on trouve par exemple [sur Kaggle](https://www.kaggle.com/tvscitechtalk/prostatecsv). Il est issu de Stamey, T.A., Kabalin, J.N., McNeal, J.E., Johnstone, I.M., Freiha, F., Redwine, E.A. and Yang, N. (1989). Prostate specific antigen in the diagnosis and treatment of adenocarcinoma of the prostate: II. radical prostatectomy treated patients, _Journal of Urology_ 141(5), 1076–1083.\n",
    "\n",
    "\n",
    "Nous avons bien ici un problème de **régression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:15:56.941830Z",
     "start_time": "2020-06-09T13:15:56.926156Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "path = \"./prostate.csv\"\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:15:57.942604Z",
     "start_time": "2020-06-09T13:15:57.940584Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:15:58.205390Z",
     "start_time": "2020-06-09T13:15:58.199877Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, [\"lcavol\", \"lweight\", \"age\", \"lbph\", \"svi\", \"lcp\", \"gleason\", \"pgg45\"]].to_numpy()\n",
    "y = df.loc[:, \"lpsa\"].to_numpy()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:15:58.778342Z",
     "start_time": "2020-06-09T13:15:58.773439Z"
    }
   },
   "outputs": [],
   "source": [
    "# split dataset for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:16:06.540750Z",
     "start_time": "2020-06-09T13:16:06.535154Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalised data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_normalized = scaler.transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "print(X_train_normalized.shape)\n",
    "print(X_test_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:18:54.827882Z",
     "start_time": "2020-06-09T13:18:54.815938Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# compute an average adjusted R2 score over 5 different train-test folds\n",
    "cv_results = cross_validate(reg, X_train_normalized, y_train, cv=5, return_train_score=True, \n",
    "                            scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# get MSE\n",
    "print(\"Mean Squared Error (validation set): {0:0.3f}\".format(-np.mean(cv_results[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Recherche du meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Linear regression + Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:21:32.011506Z",
     "start_time": "2020-06-09T13:21:32.008686Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model and alpha values to evaluate\n",
    "model = None\n",
    "alphas = np.logspace(-4, 4, 30)\n",
    "\n",
    "# define gridsearch with negative mean squared error (NMSE)\n",
    "# ...\n",
    "\n",
    "# run gridsearch\n",
    "# ...\n",
    "\n",
    "# get NMSE\n",
    "# ...\n",
    "\n",
    "# compute standard errors for NMSE\n",
    "# ...\n",
    "\n",
    "# get optimal alpha\n",
    "# ...\n",
    "\n",
    "# Transform NMSE into MSE\n",
    "# Attention : ici on reste avec la MSE plutôt que la RMSE car sklearn nous a donné les écarts-types sur la MSE \n",
    "# et la transformation de ces écarts-types en écarts-types de la RMSE n'est pas triviale.\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:48.219483Z",
     "start_time": "2020-06-09T13:09:47.565266Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot scores with a log scale in x-axis\n",
    "plt.semilogx(alphas, scores, label=\"Average RMSE\")\n",
    "plt.semilogx(alphas, (scores + std_error), 'b--')\n",
    "plt.semilogx(alphas, (scores - std_error), 'b--')\n",
    "\n",
    "# control the translucency of the fill color with alpha=0.2\n",
    "plt.fill_between(alphas, (scores + std_error), (scores - std_error), alpha=0.2)\n",
    "\n",
    "# plot best score\n",
    "plt.axhline(np.max(scores), linestyle=':', color=\"firebrick\", label=\"Best MSE\")\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(r\"$\\alpha$\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"CV score +/- std error\", fontweight=\"bold\", fontsize=15)\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title(\"Gridsearch results (score = MSE)\", fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients du modèle\n",
    "\n",
    "Le paramètre `refit=True` assure que `grid.best_estimator_` contient un modèle de régression ridge, de paramètre optimal, entrainé sur l'ensemble du jeu de données passé à `grid.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:48.492861Z",
     "start_time": "2020-06-09T13:09:48.220686Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot best estimator coefficients\n",
    "m, s, _ = plt.stem(np.arange(len(grid.best_estimator_.coef_)), grid.best_estimator_.coef_, \n",
    "                   markerfmt='o', label='Ridge', use_line_collection=True)\n",
    "plt.setp([m, s], linewidth=2)\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"Variables\", fontsize=15)\n",
    "plt.xticks(np.arange(len(grid.best_estimator_.coef_)), labels=list(df.columns[:-1]))\n",
    "\n",
    "plt.ylabel(\"Coefficient de régression\", fontsize=15)\n",
    "plt.title(\"Ridge optimisée en validation croisée\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Linear regression + Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:48.701082Z",
     "start_time": "2020-06-09T13:09:48.494784Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "# ...\n",
    "\n",
    "# define gridsearch\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:49.229519Z",
     "start_time": "2020-06-09T13:09:48.702531Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot scores with a log scale in x-axis\n",
    "plt.semilogx(alphas, scores, label=\"Average MSE\")\n",
    "plt.semilogx(alphas, (scores + std_error), 'b--')\n",
    "plt.semilogx(alphas, (scores - std_error), 'b--')\n",
    "\n",
    "# control the translucency of the fill color with alpha=0.2\n",
    "plt.fill_between(alphas, (scores + std_error), (scores - std_error), alpha=0.2)\n",
    "\n",
    "# plot best score\n",
    "plt.axhline(max(scores), linestyle=':', color=\"firebrick\", label=\"Best MSE\")\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(r\"$\\alpha$\", fontweight=\"bold\", fontsize=15)\n",
    "plt.ylabel(\"CV score +/- std error\", fontweight=\"bold\", fontsize=15)\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title(\"Gridsearch results (score = MSE)\", fontweight=\"bold\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients du modèle\n",
    "\n",
    "Le paramètre `refit=True` assure que `grid.best_estimator_` contient un Lasso, de paramètre optimal, entrainé sur l'ensemble du jeu de données passé à `grid.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T13:09:49.485425Z",
     "start_time": "2020-06-09T13:09:49.230919Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plot best estimator coefficients\n",
    "m, s, _ = plt.stem(np.arange(len(grid.best_estimator_.coef_)), grid.best_estimator_.coef_, \n",
    "                   markerfmt='o', label='Lasso', use_line_collection=True)\n",
    "plt.setp([m, s], linewidth=2)\n",
    "\n",
    "# format plot\n",
    "plt.xlabel(\"Variables\", fontsize=15)\n",
    "plt.xticks(np.arange(len(grid.best_estimator_.coef_)), labels=list(df.columns[:-1]))\n",
    "\n",
    "plt.ylabel(\"Coefficient de régression\", fontsize=15)\n",
    "plt.title(\"Lasso optimisé en validation croisée\", fontsize=20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quel est le meilleur modèle prédictif ? Quelles sont les variables les plus utiles pour la prédiction du PSA ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
